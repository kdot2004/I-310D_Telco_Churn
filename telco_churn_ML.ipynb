{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618e0a4e",
   "metadata": {},
   "source": [
    "# Thought Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c088e",
   "metadata": {},
   "source": [
    "We test 4 models:\n",
    "- Logisitic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boosting\n",
    "\n",
    "Each of the models were tested using several methods to improve their performance, including normalized/scaled features, sampling methods (SMOTE), feature selection, and hyperparameter tuning. \n",
    "\n",
    "Currently we evaluated the models based off the Churned class, which is represented by a 1. For the churned class we wanted to prioritize f1-score because it balances precision and recall. In churn dection we couldn't figure out if we wanted to prioritize identifying false positives or false negatives so we chose f1 to balance the two. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef858e",
   "metadata": {},
   "source": [
    "# Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbaa86b",
   "metadata": {},
   "source": [
    "## Baseline Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "312b0737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>senior_citizen_yes</th>\n",
       "      <th>partner_yes</th>\n",
       "      <th>dependents_yes</th>\n",
       "      <th>phone_service_yes</th>\n",
       "      <th>paperless_billing_yes</th>\n",
       "      <th>multiple_lines_no</th>\n",
       "      <th>...</th>\n",
       "      <th>streaming_tv_yes</th>\n",
       "      <th>streaming_movies_no</th>\n",
       "      <th>streaming_movies_yes</th>\n",
       "      <th>contract_month-to-month</th>\n",
       "      <th>contract_one_year</th>\n",
       "      <th>payment_method_bank_transfer</th>\n",
       "      <th>payment_method_electronic_check</th>\n",
       "      <th>payment_method_mailed_check</th>\n",
       "      <th>churn_value</th>\n",
       "      <th>cbrt_total_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.764407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.332704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>99.65</td>\n",
       "      <td>820.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.361804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>104.80</td>\n",
       "      <td>3046.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.495916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>103.70</td>\n",
       "      <td>5036.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17.141041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure_months  monthly_charges  total_charges  gender_male  \\\n",
       "0              2            53.85         108.15            1   \n",
       "1              2            70.70         151.65            0   \n",
       "2              8            99.65         820.50            0   \n",
       "3             28           104.80        3046.05            0   \n",
       "4             49           103.70        5036.30            1   \n",
       "\n",
       "   senior_citizen_yes  partner_yes  dependents_yes  phone_service_yes  \\\n",
       "0                   0            0               0                  1   \n",
       "1                   0            0               1                  1   \n",
       "2                   0            0               1                  1   \n",
       "3                   0            1               1                  1   \n",
       "4                   0            0               1                  1   \n",
       "\n",
       "   paperless_billing_yes  multiple_lines_no  ...  streaming_tv_yes  \\\n",
       "0                      1                  1  ...                 0   \n",
       "1                      1                  1  ...                 0   \n",
       "2                      1                  0  ...                 1   \n",
       "3                      1                  0  ...                 1   \n",
       "4                      1                  0  ...                 1   \n",
       "\n",
       "   streaming_movies_no  streaming_movies_yes  contract_month-to-month  \\\n",
       "0                    1                     0                        1   \n",
       "1                    1                     0                        1   \n",
       "2                    0                     1                        1   \n",
       "3                    0                     1                        1   \n",
       "4                    0                     1                        1   \n",
       "\n",
       "   contract_one_year  payment_method_bank_transfer  \\\n",
       "0                  0                             0   \n",
       "1                  0                             0   \n",
       "2                  0                             0   \n",
       "3                  0                             0   \n",
       "4                  0                             1   \n",
       "\n",
       "   payment_method_electronic_check  payment_method_mailed_check  churn_value  \\\n",
       "0                                0                            1            1   \n",
       "1                                1                            0            1   \n",
       "2                                1                            0            1   \n",
       "3                                1                            0            1   \n",
       "4                                0                            0            1   \n",
       "\n",
       "   cbrt_total_charges  \n",
       "0            4.764407  \n",
       "1            5.332704  \n",
       "2            9.361804  \n",
       "3           14.495916  \n",
       "4           17.141041  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Read in original dataframe\n",
    "df = pd.read_csv('telco_churn_encoded.csv')\n",
    "\n",
    "#Read in normalized dataframe \n",
    "normalized_df = pd.read_csv('gnb_logreg_telco_churn.csv') #Normalized total_charges by applying a cube root transformation\n",
    "\n",
    "#Check head\n",
    "normalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46aeda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b21cf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure_months</th>\n",
       "      <th>monthly_charges</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>cbrt_total_charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.010310</td>\n",
       "      <td>0.117646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.521891</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.149401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.809950</td>\n",
       "      <td>0.092511</td>\n",
       "      <td>0.374539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.861194</td>\n",
       "      <td>0.349325</td>\n",
       "      <td>0.661424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.850249</td>\n",
       "      <td>0.578987</td>\n",
       "      <td>0.809228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tenure_months  monthly_charges  total_charges  cbrt_total_charges\n",
       "0       0.027778         0.354229       0.010310            0.117646\n",
       "1       0.027778         0.521891       0.015330            0.149401\n",
       "2       0.111111         0.809950       0.092511            0.374539\n",
       "3       0.388889         0.861194       0.349325            0.661424\n",
       "4       0.680556         0.850249       0.578987            0.809228"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scale the dataset\n",
    "#Import min-max scaling from scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Initialize list of columns to scale\n",
    "scaled_cols = ['tenure_months', 'monthly_charges', 'total_charges', 'cbrt_total_charges']\n",
    "\n",
    "#Initialize scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "#Make a copy of the normalized dataframe, called scaled_df\n",
    "scaled_df = normalized_df.copy()\n",
    "\n",
    "#Apply the scaler to the scaled dataframe\n",
    "scaled_df[scaled_cols] = scaler.fit_transform(normalized_df[scaled_cols])\n",
    "\n",
    "#Check result\n",
    "scaled_df[['tenure_months', 'monthly_charges', 'total_charges', 'cbrt_total_charges']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aea6c",
   "metadata": {},
   "source": [
    "Documentation for min-max scaling: https://www.kaggle.com/code/alexisbcook/scaling-and-normalization\n",
    "\n",
    "**Why it's important:** \n",
    "\n",
    "When we orignally tried to run the logisitc regression we were was getting a max iterations warning message. While not completely aware of what this error message meant, we understood that to fix this problem we had to scale our numerical features. What scaling does it change the range of the data. For Min-Max scaling specifically it changes the range of the data to zeros (0) and one's (1). What scaling allows us to do is to compare our numerical features on equal footing. Machine learning models, especially linear models might give more weight to larger numerical values as opposed to smaller numerical values. This is especially true with distance based algorithms such as K-Nearest Neighbors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ec779ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.63%\n",
      "Best Cross-Validation Score: 75.91\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1525\n",
      "           1       0.53      0.81      0.64       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.72      2113\n",
      "weighted avg       0.80      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y (first I'll test without cube root total_charges)\n",
    "X = scaled_df.drop(columns=['churn_value', 'cbrt_total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1331bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.01%\n",
      "Best Cross-Validation Score: 76.46\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81      1525\n",
      "           1       0.53      0.80      0.64       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.72      2113\n",
      "weighted avg       0.80      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y (first I'll test without total_charges)\n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f846c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.73%\n",
      "Best Cross-Validation Score: 75.85\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1525\n",
      "           1       0.53      0.81      0.64       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.72      2113\n",
      "weighted avg       0.80      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y (first I'll test without either)\n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges', 'cbrt_total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct a train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f172c26",
   "metadata": {},
   "source": [
    "**Note:** Not much difference in model performance when using total charges and it's cubed version. The purpose behind testing the different features of total charges is because from our earlier analysis we saw that total charges was highly correlated with several other features. Thus we thought it might not have been that important of a feature to the model. However, the differences in performance wasn't anything substantial. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603c99c1",
   "metadata": {},
   "source": [
    "## Model 2: Sampling Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867f159",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2331d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from collections import Counter #Use to count the class distribution of our response variable\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b7137b",
   "metadata": {},
   "source": [
    "**What is SMOTE:**\n",
    "\n",
    "**Synthetic Minority Oversampling** is a sampling technique that is used to address class imbalance within machine learning classification tasks. Given our current dataset of churns and from our EDA we saw that around 26% of customers churned, meaning there is a substantial class imbalance. What class imbalance does is introduce bias into the model against the minority class (churned customers), meaning that the performance metrics for predicted churn is worse than it is for customers predicted not to churn.\n",
    "\n",
    "What **SMOTE** does to counteract this is create synthetic samples of the minority class (churned customers) to make the class distribution even. It works by generating new, similar examples based on existing ones rather than just duplicating them. The goal is to increase performance for predicted churn customers.\n",
    "\n",
    "**Documentation:** https://www.geeksforgeeks.org/smote-for-imbalanced-classification-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3585a8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 76.10%\n",
      "Best Cross-Validation Score: 81.14\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82      1525\n",
      "           1       0.55      0.77      0.64       588\n",
      "\n",
      "    accuracy                           0.76      2113\n",
      "   macro avg       0.72      0.76      0.73      2113\n",
      "weighted avg       0.80      0.76      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Re-conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48b27f0",
   "metadata": {},
   "source": [
    "Doesn't appear to be much of a effect for SMOTE on the logisitic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce09852",
   "metadata": {},
   "source": [
    "### Random Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca13289",
   "metadata": {},
   "source": [
    "**What is Random Under-Sampling:**\n",
    "\n",
    "**Random Under-Sampling** is another sampling technique used in classification tasks where there is a class imbalance. As opposed to SMOTE instead of creating new instances of the minority class (churned customers), random undersampling randomly removes rows of data from the majority class (customers who didn't churn), so that the numbers of each class align. \n",
    "\n",
    "**Documentation:** https://www.geeksforgeeks.org/handling-imbalanced-data-for-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebce103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before under-sampling: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after under-sampling: Counter({0: 1281, 1: 1281})\n",
      "Accuracy: 75.06%\n",
      "Best Cross-Validation Score: 81.14\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81      1525\n",
      "           1       0.53      0.81      0.64       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.73      2113\n",
      "weighted avg       0.81      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import imblearn under_sampling library\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Prepare X and y \n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before under-sampling\n",
    "print(f\"Class Distribution before under-sampling: {Counter(y_train)}\")\n",
    "\n",
    "#Apply random under-sampling to reduce majority class\n",
    "underS = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "#Redo train split\n",
    "X_under, y_under = underS.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after under-sampling\n",
    "print(f\"Class Distribution after under-sampling: {Counter(y_under)}\")\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_under, y_under)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdb9978",
   "metadata": {},
   "source": [
    "**Note:** Compared to SMOTE, random undersampling slightly boosted the recall for churned customers, meaning the model was better at correctly identifying customers who actually churned, reducing the number of false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02966920",
   "metadata": {},
   "source": [
    "## Model 3: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61598f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ee4799",
   "metadata": {},
   "source": [
    "### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29ea13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import filter method\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8538b",
   "metadata": {},
   "source": [
    "**Explanation for SelectKBest (Filter Method):**\n",
    "\n",
    "`SelectKBest` is a filter based feature selection method. What it does is select features independently from the machine learning algorithm. It does this based off several statistical measures to score and rank features. We chose to use mutual information classifier as the statistical test to feed into the filter method. \n",
    "\n",
    "**Explanation for Mutual Information Classifier:**\n",
    "\n",
    "The reason I'm using mutual information classifier on the filter method is because it's best for datasets that have a mix of numerical and cateogorial features. Although I do have more categorical than numerical it's still is useful in this situation. \n",
    "\n",
    "**Documentation:** https://medium.com/@Kavya2099/optimizing-performance-selectkbest-for-efficient-feature-selection-in-machine-learning-3b635905ed48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "baad2f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['tenure_months', 'monthly_charges', 'partner_yes', 'dependents_yes',\n",
      "       'internet_service_fiber_optic', 'online_security_no',\n",
      "       'online_backup_no', 'device_protection_no', 'tech_support_no',\n",
      "       'streaming_tv_no', 'streaming_movies_no', 'contract_month-to-month',\n",
      "       'contract_one_year', 'payment_method_electronic_check',\n",
      "       'cbrt_total_charges'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Find the best features using the filter method\n",
    "\n",
    "#Use mutual info classifier due to combo of categorical and numerical features \n",
    "selector = SelectKBest(mutual_info_classif, k=15) #Select top 15 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6138fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 75.44%\n",
      "Best Cross-Validation Score: 80.79\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81      1525\n",
      "           1       0.54      0.81      0.65       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.73      2113\n",
      "weighted avg       0.81      0.75      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df[selected_features] #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Re-conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit logistic regression model\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "logreg.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(logreg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79a50b",
   "metadata": {},
   "source": [
    "## Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "34b9a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'partner_yes', 'dependents_yes',\n",
      "       'internet_service_fiber_optic', 'online_security_no',\n",
      "       'online_backup_no', 'device_protection_no', 'tech_support_no',\n",
      "       'streaming_tv_no', 'streaming_movies_no', 'contract_month-to-month',\n",
      "       'contract_one_year', 'payment_method_electronic_check',\n",
      "       'cbrt_total_charges'],\n",
      "      dtype='object')\n",
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 75.44%\n",
      "Best Cross-Validation Score: 80.79\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.73      0.81      1525\n",
      "           1       0.54      0.81      0.65       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.77      0.73      2113\n",
      "weighted avg       0.81      0.75      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import wrapper method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Initialize logisitic regression model\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(log_reg, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = scaled_df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Fit on training data\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_tree = log_reg.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(log_reg, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb029a3a",
   "metadata": {},
   "source": [
    "**Explanation of Wrapper Method:**\n",
    "\n",
    "The wrapper method or Recursive Feature Elimination (RFE) is a commonly used feature selection method. What the wrapper method/RFE does, is train the model based off the features, then iteratively remove the least important features to the model. It does this one by one until left with the specified number of features. Where the wrapper method differs from the filter method is that is ranks features based off how well they individually boost the models performance as opposed to statistical tests. \n",
    "\n",
    "\n",
    "**Result from classification report:**\n",
    "\n",
    "Very similar result to the filter method. Both model's can be considered the same. \n",
    "\n",
    "**Documentation:** https://medium.com/@rithpansanga/logistic-regression-for-feature-selection-selecting-the-right-features-for-your-model-410ca093c5e0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94167e64",
   "metadata": {},
   "source": [
    "## Logistic Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0722d44c",
   "metadata": {},
   "source": [
    "**What is GridSearchCV:**\n",
    "\n",
    "GridSearchCV is a method from scikit-learn which works through multiple combinations of parameter tuning to provide the best set of parameters from the defined list of parameters (`param_grid`). Overall it's used to optimize the model's performance by providing the best combination of hyperparameters. \n",
    "\n",
    "**Documentation:** https://www.geeksforgeeks.org/how-to-optimize-logistic-regression-performance/\n",
    "\n",
    "**Note:**\n",
    "\n",
    "I used the same parameter grid from the geeksforgeeks link I posted above. I honestly have never used GridSearchCV for logisitic regression before so I wasn't too aware of the parameter tuning. For a more in depth look at each of the parameters of a logisitic regression look at the geeksforgeeks link above and read from scikit-learns documentation on logisitic regression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772a6b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1600 candidates, totalling 8000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': np.float64(0.615848211066026), 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy: 81.50%\n",
      "Best Cross-Validation Score: 81.16\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88      1525\n",
      "           1       0.70      0.59      0.64       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.77      0.75      0.76      2113\n",
      "weighted avg       0.81      0.81      0.81      2113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "5200 fits failed out of a total of 8000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 75, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "400 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1204, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.74016227 ...        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Import numpy\n",
    "import numpy as np\n",
    "\n",
    "#Define a parameter grid\n",
    "param_grid = {\n",
    "    'penalty':['l1','l2','elasticnet','none'],\n",
    "    'C' : np.logspace(-4,4,20),\n",
    "    'solver': ['lbfgs','newton-cg','liblinear','sag','saga'],\n",
    "    'max_iter'  : [100,1000,2500,5000]\n",
    "}\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns=['churn_value', 'total_charges'])\n",
    "y = scaled_df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize logisitc regression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "#Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(logreg, param_grid=param_grid, cv=5, verbose=True, n_jobs=1)\n",
    "\n",
    "#Fit grid to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best hyperparameters\n",
    "print(f\"Best Hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "#Put the best parameters on the logreg model\n",
    "logreg = grid_search.best_estimator_\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_log = logreg.predict(X_test)\n",
    "\n",
    "#Get best cross-val score\n",
    "score_mean = grid_search.best_score_ * 100\n",
    "\n",
    "#Display accuracy and classification\n",
    "accuracy = accuracy_score(y_test, y_pred_log) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba28b1",
   "metadata": {},
   "source": [
    "**Results from classification Report:**\n",
    "\n",
    "The GridSearch powered logisitic regression significantly improved in precision (for churned customers) however, it suffered in recall as a result. Regardless the f1-score didn't see much improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd5a74",
   "metadata": {},
   "source": [
    "**Error Explanation:**\n",
    "\n",
    "What this error \"The max_iter was reached which means the coef_ did not converge\" means is that there's a chance that my model could of reached better parameters but the full number of iterations was reached before this could happen. Overall it means my model could've been better. I could look into how to fix this error but I honestly don't know how to. Rather than trying to fix this issues I'll just test out other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3db12",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafcb954",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5320019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.49%\n",
      "Best Cross-Validation Score: 73.22\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1525\n",
      "           1       0.54      0.53      0.54       588\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.68      0.68      0.68      2113\n",
      "weighted avg       0.74      0.74      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import decision tree and other libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42) #Decision Tree without any hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df33364",
   "metadata": {},
   "source": [
    "Performs pretty poorly for churned customers, especially compared to the baseline logisitic regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a9878",
   "metadata": {},
   "source": [
    "## Decision Tree with Normalized Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2228292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.30%\n",
      "Best Cross-Validation Score: 73.22\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82      1525\n",
      "           1       0.54      0.50      0.52       588\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.68      0.67      0.67      2113\n",
      "weighted avg       0.74      0.74      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use normalized features to see if there's a difference\n",
    "\n",
    "#Prepare X and y\n",
    "X = normalized_df.drop(columns= ['churn_value', 'total_charges']) #Explanatory variables\n",
    "y = normalized_df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42) #Decision Tree without any hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb7707",
   "metadata": {},
   "source": [
    "No improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346cc1ad",
   "metadata": {},
   "source": [
    "## Decision Tree with Normalized and Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283860b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.44%\n",
      "Best Cross-Validation Score: 72.95\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      1525\n",
      "           1       0.54      0.53      0.53       588\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.68      0.68      0.68      2113\n",
      "weighted avg       0.74      0.74      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use scaled + normalized features to see if there's a difference \n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns='churn_value') #Explanatory variables\n",
    "y = scaled_df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42) #Decision Tree without any hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9c8c5",
   "metadata": {},
   "source": [
    "No improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69759d8",
   "metadata": {},
   "source": [
    "## Decision Tree with different sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b68fb1",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 73.12%\n",
      "Best Cross-Validation Score: 73.22\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81      1525\n",
      "           1       0.52      0.57      0.54       588\n",
      "\n",
      "    accuracy                           0.73      2113\n",
      "   macro avg       0.67      0.68      0.68      2113\n",
      "weighted avg       0.74      0.73      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Re-conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3682d1e",
   "metadata": {},
   "source": [
    "Still under whelming performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa1a92",
   "metadata": {},
   "source": [
    "### Random Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf37b4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before under-sampling: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after under-sampling: Counter({0: 1281, 1: 1281})\n",
      "Accuracy: 67.96%\n",
      "Best Cross-Validation Score: 73.22\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75      1525\n",
      "           1       0.45      0.71      0.55       588\n",
      "\n",
      "    accuracy                           0.68      2113\n",
      "   macro avg       0.65      0.69      0.65      2113\n",
      "weighted avg       0.74      0.68      0.70      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import imblearn under_sampling library\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Prepare X and y \n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before under-sampling\n",
    "print(f\"Class Distribution before under-sampling: {Counter(y_train)}\")\n",
    "\n",
    "#Apply random under-sampling to reduce majority class\n",
    "underS = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "#Redo train-test split\n",
    "X_under, y_under = underS.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after under-sampling\n",
    "print(f\"Class Distribution after under-sampling: {Counter(y_under)}\")\n",
    "\n",
    "#Initialize and fit decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_under, y_under)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83562697",
   "metadata": {},
   "source": [
    "Even worse performance for churned customers despite the rise in recall which came at the cost of precision and f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b24d8f4",
   "metadata": {},
   "source": [
    "## Decision Tree with Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97d63e1",
   "metadata": {},
   "source": [
    "### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bca0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import filter method and mutual info classifier\n",
    "from sklearn.feature_selection import SelectKBest \n",
    "from sklearn.feature_selection import mutual_info_classif #B/c we have a mix of categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ef088430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e2c37fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['tenure_months', 'internet_service_fiber_optic', 'online_security_no',\n",
      "       'tech_support_no', 'contract_month-to-month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Find the best features using the filter method\n",
    "\n",
    "#Use mutual info classifier due to combo of categorical and numerical features \n",
    "selector = SelectKBest(mutual_info_classif, k=5) #Select top 5 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de62a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.33%\n",
      "Best Cross-Validation Score: 77.61\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85      1525\n",
      "           1       0.60      0.54      0.57       588\n",
      "\n",
      "    accuracy                           0.77      2113\n",
      "   macro avg       0.72      0.70      0.71      2113\n",
      "weighted avg       0.77      0.77      0.77      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Re-prepare X and y\n",
    "X = df[selected_features]\n",
    "y = df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42) #Decision Tree without any hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af55a5b5",
   "metadata": {},
   "source": [
    "Still pretty bad performance for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b2947d",
   "metadata": {},
   "source": [
    "### Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62741f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'total_charges', 'gender_male',\n",
      "       'senior_citizen_yes', 'partner_yes', 'dependents_yes',\n",
      "       'paperless_billing_yes', 'internet_service_fiber_optic',\n",
      "       'online_security_yes', 'online_backup_no', 'device_protection_no',\n",
      "       'tech_support_no', 'contract_month-to-month',\n",
      "       'payment_method_electronic_check'],\n",
      "      dtype='object')\n",
      "Accuracy: 74.16%\n",
      "Best Cross-Validation Score: 73.22\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82      1525\n",
      "           1       0.54      0.53      0.53       588\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.68      0.68      0.68      2113\n",
      "weighted avg       0.74      0.74      0.74      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import wrapper method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(decision_tree, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for decision tree\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f694e",
   "metadata": {},
   "source": [
    "Bad performance yet again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985da49",
   "metadata": {},
   "source": [
    "## Decision Tree with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f483105",
   "metadata": {},
   "source": [
    "Again I use GridSearchCV to optimize the parameters of the Decision Tree. For more information on the parameters of a decision tree:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d63ec53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Best cross-validation accuracy:  0.7884381338742393\n",
      "Accuracy: 78.89%\n",
      "Best Cross-Validation Score: 78.76\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1525\n",
      "           1       0.60      0.70      0.65       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.76      0.75      2113\n",
      "weighted avg       0.80      0.79      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables (No feature selection)\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#Define parameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#Set up GridSearchCV with 5-fold cross validation\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "#Put best parameters on decision tree\n",
    "decision_tree = grid_search.best_estimator_\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f07467",
   "metadata": {},
   "source": [
    "Pretty decent improvement, matches the f1-score from the logisitic regression with the filter method (65%). Relatively decent precision and recall as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be38a31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Best cross-validation accuracy:  0.7884381338742393\n",
      "Accuracy: 78.89%\n",
      "Best Cross-Validation Score: 78.76\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85      1525\n",
      "           1       0.60      0.70      0.65       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.76      0.75      2113\n",
      "weighted avg       0.80      0.79      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add more hyperparameter tuning\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables (No feature selection)\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#Define parameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "#Set up GridSearchCV with 5-fold cross validation\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "#Put best parameters on decision tree\n",
    "decision_tree = grid_search.best_estimator_\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958100bb",
   "metadata": {},
   "source": [
    "Similar performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd4ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best cross-validation accuracy:  0.7935091277890466\n",
      "Accuracy: 79.22%\n",
      "Best Cross-Validation Score: 79.38\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86      1525\n",
      "           1       0.69      0.46      0.55       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.75      0.69      0.71      2113\n",
      "weighted avg       0.78      0.79      0.78      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Prepare X and y\n",
    "X = df[selected_features] #Explanatory variables (No feature selection)\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#Define parameters grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "#Set up GridSearchCV with 5-fold cross validation\n",
    "grid_search = GridSearchCV(estimator=decision_tree, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "#Fit to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "#Put best parameters on decision tree\n",
    "decision_tree = grid_search.best_estimator_\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_tree = decision_tree.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(decision_tree, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_tree) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff1b137",
   "metadata": {},
   "source": [
    "Tried using the list of selected features from the filter method but that didn't improve performance and instead drastically reduced it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eef3ffd",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cdf761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846285a",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6799704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.99%\n",
      "Best Cross-Validation Score: 79.19\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1525\n",
      "           1       0.65      0.52      0.58       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.71      0.72      2113\n",
      "weighted avg       0.78      0.79      0.78      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42) #No hyperparameter tuning \n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c40e1",
   "metadata": {},
   "source": [
    "Not as good performance compared to the baseline logisitic regression model, but still is better than the baseline decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5f015",
   "metadata": {},
   "source": [
    "## Normalized Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a96cc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.56%\n",
      "Best Cross-Validation Score: 79.53\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1525\n",
      "           1       0.67      0.53      0.59       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.71      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = normalized_df.drop(columns=['total_charges', 'churn_value']) #Explanatory variables\n",
    "y = normalized_df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest classifier\n",
    "random_forest = RandomForestClassifier(random_state=42) #No hyperparameter tuning \n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31bbda",
   "metadata": {},
   "source": [
    "Slightly improved f1 for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556c2b26",
   "metadata": {},
   "source": [
    "## Scaled Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a579a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.12%\n",
      "Best Cross-Validation Score: 79.17\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1525\n",
      "           1       0.68      0.53      0.60       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.76      0.72      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Use scaled features to see if there's a difference \n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns='churn_value') #Explanatory variables\n",
    "y = scaled_df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize decision tree\n",
    "random_forest =  RandomForestClassifier(random_state=42) #Without any hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for random forest\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ad6bc9",
   "metadata": {},
   "source": [
    "Again improved the f1 for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0f3395",
   "metadata": {},
   "source": [
    "## Random Forest with different sampling methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ac903",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c10cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 79.51%\n",
      "Best Cross-Validation Score: 79.51\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1525\n",
      "           1       0.67      0.53      0.59       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.71      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns=['total_charges', 'churn_value']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b6d8f",
   "metadata": {},
   "source": [
    "Didn't improve performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4465eaee",
   "metadata": {},
   "source": [
    "### Random Under-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51fdc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before under-sampling: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after under-sampling: Counter({0: 1281, 1: 1281})\n",
      "Accuracy: 74.49%\n",
      "Best Cross-Validation Score: 79.51\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80      1525\n",
      "           1       0.53      0.84      0.65       588\n",
      "\n",
      "    accuracy                           0.74      2113\n",
      "   macro avg       0.72      0.77      0.72      2113\n",
      "weighted avg       0.81      0.74      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import imblearn under_sampling library\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "#Prepare X and y \n",
    "X = scaled_df.drop(columns=['total_charges', 'churn_value']) #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before under-sampling\n",
    "print(f\"Class Distribution before under-sampling: {Counter(y_train)}\")\n",
    "\n",
    "#Apply random under-sampling to reduce majority class\n",
    "underS = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "#Redo train-test split\n",
    "X_under, y_under = underS.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after under-sampling\n",
    "print(f\"Class Distribution after under-sampling: {Counter(y_under)}\")\n",
    "\n",
    "#Initialize random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_under, y_under)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b3537d",
   "metadata": {},
   "source": [
    "Best f1-score (65%) along with wrapper method powered Logistitic Regression and GridSearch powered Decision Tree. Also very high performance in recall, but at the tradeoff of lower performance for precision (for churned customers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db9592",
   "metadata": {},
   "source": [
    "## Random Forest with Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0140b3",
   "metadata": {},
   "source": [
    "### Filter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98904366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f11b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['tenure_months', 'monthly_charges', 'total_charges', 'gender_male',\n",
      "       'senior_citizen_yes', 'dependents_yes', 'paperless_billing_yes',\n",
      "       'internet_service_dsl', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_security_yes', 'online_backup_no',\n",
      "       'online_backup_yes', 'device_protection_no', 'tech_support_no',\n",
      "       'tech_support_yes', 'contract_month-to-month', 'contract_one_year',\n",
      "       'payment_method_bank_transfer', 'payment_method_electronic_check'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Find the best features using the filter method\n",
    "\n",
    "#Use mutual info classifier due to combo of categorical and numerical features \n",
    "selector = SelectKBest(mutual_info_classif, k=20) #Select top 20 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6a15ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.70%\n",
      "Best Cross-Validation Score: 78.97\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1525\n",
      "           1       0.67      0.54      0.60       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.72      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Re-prepare X and y\n",
    "X = scaled_df[selected_features]\n",
    "y = scaled_df['churn_value']\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Evaluate model\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a40206",
   "metadata": {},
   "source": [
    "Not great performance for churned customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "97d25041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 79.70%\n",
      "Best Cross-Validation Score: 78.97\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86      1525\n",
      "           1       0.67      0.54      0.60       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.72      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter method with SMOTE\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df[selected_features] #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ea29c8",
   "metadata": {},
   "source": [
    "Again, not great performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d569f12",
   "metadata": {},
   "source": [
    "### Wrapper Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01bb8e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'gender_male', 'senior_citizen_yes',\n",
      "       'partner_yes', 'dependents_yes', 'paperless_billing_yes',\n",
      "       'multiple_lines_no', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_backup_no', 'tech_support_no',\n",
      "       'contract_month-to-month', 'payment_method_electronic_check',\n",
      "       'cbrt_total_charges'],\n",
      "      dtype='object')\n",
      "Accuracy: 79.13%\n",
      "Best Cross-Validation Score: 79.51\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1525\n",
      "           1       0.65      0.54      0.59       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.71      0.72      2113\n",
      "weighted avg       0.78      0.79      0.78      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import wrapper method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Initialize random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(random_forest, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = normalized_df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7c9d8bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'gender_male', 'senior_citizen_yes',\n",
      "       'partner_yes', 'dependents_yes', 'paperless_billing_yes',\n",
      "       'multiple_lines_no', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_backup_no', 'tech_support_no',\n",
      "       'contract_month-to-month', 'payment_method_electronic_check',\n",
      "       'cbrt_total_charges'],\n",
      "      dtype='object')\n",
      "Accuracy: 79.22%\n",
      "Best Cross-Validation Score: 79.51\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1525\n",
      "           1       0.65      0.54      0.59       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.71      0.73      2113\n",
      "weighted avg       0.78      0.79      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import wrapper method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Initialize random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(random_forest, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = scaled_df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8250fde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'total_charges', 'gender_male',\n",
      "       'senior_citizen_yes', 'partner_yes', 'dependents_yes',\n",
      "       'paperless_billing_yes', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_backup_no', 'tech_support_no',\n",
      "       'contract_month-to-month', 'payment_method_electronic_check',\n",
      "       'cbrt_total_charges'],\n",
      "      dtype='object')\n",
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 80.12%\n",
      "Best Cross-Validation Score: 79.17\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87      1525\n",
      "           1       0.68      0.53      0.60       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.76      0.72      0.73      2113\n",
      "weighted avg       0.79      0.80      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#With SMOTE\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns='churn_value') #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Initialize random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(random_forest, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = scaled_df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Initialize and fit random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(random_forest, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423f4fc0",
   "metadata": {},
   "source": [
    "## Random Forest with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc53cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RandomSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480faaf9",
   "metadata": {},
   "source": [
    "**What is RandomSearchCV:** \n",
    "\n",
    "RandomSearchCV is another hyperparameter optimization module from scikit-learn, similar to GridSearchCV. RandomSearchCV works by sampling random combinations of hyperparameters from the parameter grid (`param_grid`) and then evaluating them using 5 fold cross-validation. It continues to repeat this process until it's met the defined number of iterations (which we tested both at 25 and 100). It's important to note that RandomSearchCV doesn't explore the entire parameter grid but instead selects a random subset of it. This can be more efficient than GridSearchCv which goes through the whole parameter grid. \n",
    "\n",
    "**Documentation:** https://www.geeksforgeeks.org/comparing-randomized-search-and-grid-search-for-hyperparameter-estimation-in-scikit-learn/\n",
    "\n",
    "For the parameters of a Random forest: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ad8b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Accuracy: 80.31%\n",
      "Cross-Validation Score: 80.51\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      1525\n",
      "           1       0.67      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.76      0.73      0.74      2113\n",
      "weighted avg       0.80      0.80      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "\n",
    "#Initialize Random Search CV\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_grid, n_iter=25, cv=5, random_state=42)\n",
    "\n",
    "#Fit on training data \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters and display cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "#Get cross-validation score\n",
    "cross_val = random_search.best_score_ * 100\n",
    "\n",
    "#Put best parameters on random forest\n",
    "random_forest = random_search.best_estimator_\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Display accuracy and classification report for model\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Cross-Validation Score: {cross_val:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429b705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini', 'bootstrap': True}\n",
      "Accuracy: 80.69%\n",
      "Cross-Validation Score: 80.39\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1525\n",
      "           1       0.68      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.76      0.73      0.75      2113\n",
      "weighted avg       0.80      0.81      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Incrase the number of iterations to 100\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "\n",
    "#Initialize Random Search CV\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_grid, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "#Fit on training data \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters and display cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "#Get cross-validation score\n",
    "cross_val = random_search.best_score_ * 100\n",
    "\n",
    "#Put best parameters on random forest\n",
    "random_forest = random_search.best_estimator_\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Display accuracy and classification report for model\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Cross-Validation Score: {cross_val:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10af8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Accuracy: 80.79%\n",
      "Cross-Validation Score: 80.43\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1525\n",
      "           1       0.69      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.77      0.73      0.75      2113\n",
      "weighted avg       0.80      0.81      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Normalized Features\n",
    "\n",
    "#Prepare X and y\n",
    "X = normalized_df.drop(columns='churn_value') #Explanatory variables\n",
    "y = normalized_df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "\n",
    "#Initialize Random Search CV\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_grid, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "#Fit on training data \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters and display cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "#Get cross-validation score\n",
    "cross_val = random_search.best_score_ * 100\n",
    "\n",
    "#Put best parameters on random forest\n",
    "random_forest = random_search.best_estimator_\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Display accuracy and classification report for model\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Cross-Validation Score: {cross_val:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d051fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'entropy', 'bootstrap': True}\n",
      "Accuracy: 80.79%\n",
      "Cross-Validation Score: 80.45\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1525\n",
      "           1       0.69      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.77      0.73      0.75      2113\n",
      "weighted avg       0.80      0.81      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Scaled + Normalized Features Features\n",
    "\n",
    "#Prepare X and y\n",
    "X = scaled_df.drop(columns='churn_value') #Explanatory variables\n",
    "y = scaled_df['churn_value'] #Response variable\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize random forest model\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini','entropy']\n",
    "}\n",
    "\n",
    "#Initialize Random Search CV\n",
    "random_search = RandomizedSearchCV(estimator=random_forest, param_distributions=param_grid, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "#Fit on training data \n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters and display cross-validation score\n",
    "print(f\"Best Hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "#Get cross-validation score\n",
    "cross_val = random_search.best_score_ * 100\n",
    "\n",
    "#Put best parameters on random forest\n",
    "random_forest = random_search.best_estimator_\n",
    "\n",
    "#Make predictions\n",
    "y_pred_forest = random_forest.predict(X_test)\n",
    "\n",
    "#Display accuracy and classification report for model\n",
    "accuracy = accuracy_score(y_test, y_pred_forest) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Cross-Validation Score: {cross_val:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33554153",
   "metadata": {},
   "source": [
    "Good Precision for all the RandomSearch boosted Random Forests, but poor f1 for churned customers, especially compared to our best f1-score of 65%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3f10a",
   "metadata": {},
   "source": [
    "# Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b8811",
   "metadata": {},
   "source": [
    "## Baseline Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cb72328",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "084e1ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.64%\n",
      "Best Cross-Validation Score: 80.75\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1525\n",
      "           1       0.68      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.76      0.73      0.75      2113\n",
      "weighted avg       0.80      0.81      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable \n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize gradient boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=42) #No hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae547c28",
   "metadata": {},
   "source": [
    "Decent performance, although not the best f1 for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35812d",
   "metadata": {},
   "source": [
    "**Note:** I did also test both the normalized and scaled dataframes on the gradient boosted model, but there wasn't much of a difference in model performance so I didn't bother keep the cell blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e888c1",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2017726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 79.27%\n",
      "Best Cross-Validation Score: 80.75\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.85      1525\n",
      "           1       0.61      0.69      0.65       588\n",
      "\n",
      "    accuracy                           0.79      2113\n",
      "   macro avg       0.74      0.76      0.75      2113\n",
      "weighted avg       0.80      0.79      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable \n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Initialize gradient boosting model\n",
    "gbc_smote = GradientBoostingClassifier(random_state=42) #No hyperparameter tuning\n",
    "\n",
    "#Fit on training data\n",
    "gbc_smote.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Display class balance after SMOTE\n",
    "print(f\"Class Distribution after SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_gbc = gbc_smote.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc_smote, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9915273",
   "metadata": {},
   "source": [
    "Goes along with our other best models that achieved a 65% f1-score for churned customers\n",
    "\n",
    "Those being:\n",
    "- Logisitic Regression + Filter/Wrapper Method\n",
    "- Decision Tree + GridSearchCV\n",
    "- Random Forest + Random-Under Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f539e5f6",
   "metadata": {},
   "source": [
    "## Random Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0660a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import imblearn under_sampling library\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2b552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution before under-sampling: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution after under-sampling: Counter({0: 1281, 1: 1281})\n",
      "Accuracy: 74.54%\n",
      "Best Cross-Validation Score: 80.75\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.71      0.80      1525\n",
      "           1       0.53      0.84      0.65       588\n",
      "\n",
      "    accuracy                           0.75      2113\n",
      "   macro avg       0.72      0.78      0.72      2113\n",
      "weighted avg       0.81      0.75      0.76      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable \n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize gradient boosting model\n",
    "gbc_under = GradientBoostingClassifier(random_state=42) #No hyperparameter tuning\n",
    "\n",
    "#Display class balance before under-sampling\n",
    "print(f\"Class Distribution before under-sampling: {Counter(y_train)}\")\n",
    "\n",
    "#Apply random under-sampling to reduce majority class\n",
    "underS = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "#Redo train-test split\n",
    "X_under, y_under = underS.fit_resample(X_train, y_train)\n",
    "\n",
    "#Display class balance after under-sampling\n",
    "print(f\"Class Distribution after under-sampling: {Counter(y_under)}\")\n",
    "\n",
    "#Fit on training data\n",
    "gbc_under.fit(X_under, y_under)\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_gbc = gbc_under.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc_under, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdc46b",
   "metadata": {},
   "source": [
    "Along with our best f1-scores (65%) and very good recall. However it comes at the cost of lower precision for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310dd988",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ee204",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52d758f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['tenure_months', 'monthly_charges', 'total_charges',\n",
      "       'senior_citizen_yes', 'partner_yes', 'dependents_yes',\n",
      "       'paperless_billing_yes', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_security_yes', 'online_backup_no',\n",
      "       'device_protection_no', 'device_protection_yes', 'tech_support_no',\n",
      "       'tech_support_yes', 'streaming_tv_no', 'contract_month-to-month',\n",
      "       'contract_one_year', 'payment_method_electronic_check',\n",
      "       'payment_method_mailed_check'],\n",
      "      dtype='object')\n",
      "Accuracy: 80.31%\n",
      "Best Cross-Validation Score: 80.75\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87      1525\n",
      "           1       0.67      0.58      0.62       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.76      0.74      0.74      2113\n",
      "weighted avg       0.80      0.80      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory\n",
    "y = df['churn_value'] #Response\n",
    "\n",
    "\n",
    "#Import libraries for filter method\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "#Use mutual info classifier due to combo of categorical and numerical features \n",
    "selector = SelectKBest(mutual_info_classif, k=20) #Select top 20 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "#Put selected features on X\n",
    "X = df[selected_features] #Explanatory variables\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize Gradient boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Make predicitions on test data\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89ed03",
   "metadata": {},
   "source": [
    "Not great performance compared to the other \"best\" models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "894abd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['tenure_months', 'monthly_charges', 'total_charges',\n",
      "       'senior_citizen_yes', 'dependents_yes', 'paperless_billing_yes',\n",
      "       'internet_service_dsl', 'internet_service_fiber_optic',\n",
      "       'online_security_no', 'online_security_yes', 'online_backup_no',\n",
      "       'device_protection_no', 'device_protection_yes', 'tech_support_no',\n",
      "       'tech_support_yes', 'streaming_tv_no', 'streaming_movies_no',\n",
      "       'contract_month-to-month', 'contract_one_year',\n",
      "       'payment_method_electronic_check'],\n",
      "      dtype='object')\n",
      "Class Distribution before SMOTE: Counter({0: 3649, 1: 1281})\n",
      "Class Distribution before SMOTE: Counter({1: 3649, 0: 3649})\n",
      "Accuracy: 77.99%\n",
      "Best Cross-Validation Score: 80.48\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      1525\n",
      "           1       0.58      0.72      0.65       588\n",
      "\n",
      "    accuracy                           0.78      2113\n",
      "   macro avg       0.73      0.76      0.74      2113\n",
      "weighted avg       0.80      0.78      0.79      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#With SMOTE\n",
    "\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory\n",
    "y = df['churn_value'] #Response\n",
    "\n",
    "\n",
    "#Import libraries for filter method\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "#Use mutual info classifier due to combo of categorical and numerical features \n",
    "selector = SelectKBest(mutual_info_classif, k=20) #Select top 20 features\n",
    "X_new = selector.fit_transform(X, y)\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[selector.get_support()]\n",
    "print(f\"Selected Features: {selected_features}\")\n",
    "\n",
    "#Put selected features on X\n",
    "X = df[selected_features] #Explanatory variables\n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "#Apply SMOTE to oversample the minority class\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=42) #Initialize SMOTE\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "#Initialize Gradient boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "gbc.fit(X_train_res, y_train_res)\n",
    "\n",
    "#Display class balance before SMOTE\n",
    "print(f\"Class Distribution before SMOTE: {Counter(y_train_res)}\")\n",
    "\n",
    "#Make predicitions on test data\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Model Evaluation\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1cb504",
   "metadata": {},
   "source": [
    "### Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73857470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features using the Wrapper Method: Index(['tenure_months', 'monthly_charges', 'total_charges', 'dependents_yes',\n",
      "       'paperless_billing_yes', 'internet_service_dsl',\n",
      "       'internet_service_fiber_optic', 'online_security_no',\n",
      "       'online_backup_no', 'device_protection_no', 'tech_support_no',\n",
      "       'streaming_movies_no', 'contract_month-to-month', 'contract_one_year',\n",
      "       'payment_method_electronic_check'],\n",
      "      dtype='object')\n",
      "Accuracy: 80.03%\n",
      "Best Cross-Validation Score: 80.48\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.87      1525\n",
      "           1       0.66      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.80      2113\n",
      "   macro avg       0.75      0.73      0.74      2113\n",
      "weighted avg       0.79      0.80      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import wrapper method\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Initialize gradint boosting model\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "\n",
    "#Initialize RFE and select top 15 features\n",
    "rfe = RFE(random_forest, n_features_to_select=15)\n",
    "rfe.fit(X, y) #Fit on X and y\n",
    "\n",
    "#Print out selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(f\"Selected Features using the Wrapper Method: {selected_features}\")\n",
    "\n",
    "#Prepare X \n",
    "X_selected = df[selected_features]\n",
    "\n",
    "#Conduct train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Fit on training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Conduct 5-fold cross-validation \n",
    "scores = cross_val_score(gbc, X, y, cv=5, scoring='accuracy')\n",
    "score_mean = scores.mean() * 100\n",
    "\n",
    "#Display accuracy and classification report for logistic regression\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562432cf",
   "metadata": {},
   "source": [
    "## Gradient Boosting with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9ef24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KRAyu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2881: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 0.1, 'max_depth': 3, 'max_features': 5, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Accuracy: 80.69%\n",
      "Best Cross-Validation Score: 81.18\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87      1525\n",
      "           1       0.68      0.57      0.62       588\n",
      "\n",
      "    accuracy                           0.81      2113\n",
      "   macro avg       0.76      0.73      0.75      2113\n",
      "weighted avg       0.80      0.81      0.80      2113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': [1, 3, 5],\n",
    "}\n",
    "\n",
    "#Prepare X and y\n",
    "X = df.drop(columns='churn_value') #Explanatory variables\n",
    "y = df['churn_value'] #Response variable \n",
    "\n",
    "#Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "\n",
    "#Initialize gradient boosting model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "#Initialize gridsearchcv\n",
    "grid_search = GridSearchCV(estimator=gbc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=1)\n",
    "\n",
    "#Fit on training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Get best parameters\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "#Put best parameters on model\n",
    "gbc = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "#Make predictions on testing data\n",
    "y_pred_gbc = gbc.predict(X_test)\n",
    "\n",
    "#Model evaluation\n",
    "\n",
    "#Get cross-val score\n",
    "score_mean = grid_search.best_score_ * 100\n",
    "\n",
    "#Display accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, y_pred_gbc) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Best Cross-Validation Score: {score_mean:.2f}\")\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test,y_pred_gbc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72212c25",
   "metadata": {},
   "source": [
    "Not better than our \"Best\" models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ef20e",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df65253",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "\n",
    "Given our evalaution metric for churned customers being f1-score. We have 4 models tied currently for the best f1-score of 65% for churned customers. \n",
    "\n",
    "- Logisitic Regression + SMOTE + Filter/Wrapper Method \n",
    "- Decision Tree + GridSearchCV\n",
    "- Random Forest + Under-Sampling\n",
    "- Gradient Boosting Model + SMOTE\n",
    "\n",
    "In terms of our simpliest model with the best performance it would probably be the Logisitic Regression Model with scaled/normalized features, which had a f1-score of 64% for churned customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d164b68",
   "metadata": {},
   "source": [
    "## Let's further dive into our \"Best Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8eec76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's\n",
      "Note: Metrics involve only class 1: Churned Customers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_132a2_row0_col1, #T_132a2_row2_col3, #T_132a2_row3_col0, #T_132a2_row3_col2, #T_132a2_row4_col3 {\n",
       "  color: white;\n",
       "  background-color: green;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_132a2_row1_col1, #T_132a2_row2_col0, #T_132a2_row2_col2, #T_132a2_row3_col3, #T_132a2_row4_col2 {\n",
       "  color: white;\n",
       "  background-color: red;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_132a2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_132a2_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_132a2_level0_col1\" class=\"col_heading level0 col1\" >Cross-Val Score</th>\n",
       "      <th id=\"T_132a2_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_132a2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_132a2_level0_col4\" class=\"col_heading level0 col4\" >F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_132a2_level0_row0\" class=\"row_heading level0 row0\" >Log Reg + SMOTE+ Filter</th>\n",
       "      <td id=\"T_132a2_row0_col0\" class=\"data row0 col0\" >75.44%</td>\n",
       "      <td id=\"T_132a2_row0_col1\" class=\"data row0 col1\" >80.79%</td>\n",
       "      <td id=\"T_132a2_row0_col2\" class=\"data row0 col2\" >54%</td>\n",
       "      <td id=\"T_132a2_row0_col3\" class=\"data row0 col3\" >81%</td>\n",
       "      <td id=\"T_132a2_row0_col4\" class=\"data row0 col4\" >65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_132a2_level0_row1\" class=\"row_heading level0 row1\" >Decision Tree + Grid</th>\n",
       "      <td id=\"T_132a2_row1_col0\" class=\"data row1 col0\" >78.89%</td>\n",
       "      <td id=\"T_132a2_row1_col1\" class=\"data row1 col1\" >78.76%</td>\n",
       "      <td id=\"T_132a2_row1_col2\" class=\"data row1 col2\" >60%</td>\n",
       "      <td id=\"T_132a2_row1_col3\" class=\"data row1 col3\" >70%</td>\n",
       "      <td id=\"T_132a2_row1_col4\" class=\"data row1 col4\" >65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_132a2_level0_row2\" class=\"row_heading level0 row2\" >Random Forest + Random-Under</th>\n",
       "      <td id=\"T_132a2_row2_col0\" class=\"data row2 col0\" >74.49%</td>\n",
       "      <td id=\"T_132a2_row2_col1\" class=\"data row2 col1\" >79.51%</td>\n",
       "      <td id=\"T_132a2_row2_col2\" class=\"data row2 col2\" >53%</td>\n",
       "      <td id=\"T_132a2_row2_col3\" class=\"data row2 col3\" >84%</td>\n",
       "      <td id=\"T_132a2_row2_col4\" class=\"data row2 col4\" >65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_132a2_level0_row3\" class=\"row_heading level0 row3\" >Gradient Boost + SMOTE</th>\n",
       "      <td id=\"T_132a2_row3_col0\" class=\"data row3 col0\" >79.27%</td>\n",
       "      <td id=\"T_132a2_row3_col1\" class=\"data row3 col1\" >80.75%</td>\n",
       "      <td id=\"T_132a2_row3_col2\" class=\"data row3 col2\" >61%</td>\n",
       "      <td id=\"T_132a2_row3_col3\" class=\"data row3 col3\" >69%</td>\n",
       "      <td id=\"T_132a2_row3_col4\" class=\"data row3 col4\" >65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_132a2_level0_row4\" class=\"row_heading level0 row4\" >Gradient Boosting + Random-Under</th>\n",
       "      <td id=\"T_132a2_row4_col0\" class=\"data row4 col0\" >74.54%</td>\n",
       "      <td id=\"T_132a2_row4_col1\" class=\"data row4 col1\" >80.75%</td>\n",
       "      <td id=\"T_132a2_row4_col2\" class=\"data row4 col2\" >53%</td>\n",
       "      <td id=\"T_132a2_row4_col3\" class=\"data row4 col3\" >84%</td>\n",
       "      <td id=\"T_132a2_row4_col4\" class=\"data row4 col4\" >65%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x23fffaac620>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import numpy\n",
    "import numpy as np\n",
    "\n",
    "#Create a dataframe of each of our best models and their given perofmrance metrics\n",
    "print(\"Best Model's\\nNote: Metrics involve only class 1: Churned Customers\")\n",
    "model_eval = pd.DataFrame({\n",
    "    'Accuracy': [75.44, 78.89, 74.49, 79.27, 74.54],\n",
    "    'Cross-Val Score': [80.79, 78.76, 79.51, 80.75, 80.75],\n",
    "    'Precision': [54, 60, 53, 61, 53],\n",
    "    'Recall': [81, 70, 84, 69, 84],\n",
    "    'F1-Score': [65, 65, 65, 65, 65],\n",
    "}, index=['Log Reg + SMOTE+ Filter', 'Decision Tree + Grid', 'Random Forest + Random-Under', 'Gradient Boost + SMOTE', \n",
    "          'Gradient Boosting + Random-Under'])\n",
    "\n",
    "#Change formatting by adding percentages\n",
    "model_eval = model_eval.style.format({\n",
    "    'Accuracy': \"{}%\",\n",
    "    'Cross-Val Score': \"{}%\",\n",
    "    'Precision': \"{}%\",\n",
    "    'Recall': \"{}%\",\n",
    "    'F1-Score': \"{}%\"\n",
    "})\n",
    "\n",
    "#Define a function to highlight the minimum and maximum metrics\n",
    "def highlight_max(x, props='color:white;background-color: green; font-weight:bold;'):\n",
    "    return np.where(x == np.nanmax(x.values), props, '')\n",
    "def highlight_min(x, props='color:white;background-color: red; font-weight:bold;'):\n",
    "    return np.where(x==np.nanmin(x.values), props, '')\n",
    "\n",
    "#Get all columns expect for f1-score\n",
    "columns_to_style = model_eval.columns[0:4]\n",
    "\n",
    "#Apply to dataframe (expect for f1-score)\n",
    "style_model_eval = model_eval.apply(highlight_max, axis=0, subset=columns_to_style)\n",
    "style_model_eval = model_eval.apply(highlight_min, axis=0, subset=columns_to_style)\n",
    "\n",
    "#Display\n",
    "display(style_model_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900e71a",
   "metadata": {},
   "source": [
    "## What is our best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf217b8",
   "metadata": {},
   "source": [
    "From analyzing the classification report for churned customers, **two models clearly stand out**:\n",
    "\n",
    "1. **Gradient Boost + SMOTE**\n",
    "\n",
    "    This model is the **most accurate**, but given our class imbalance, accuracy isnâ€™t the most reliable metric. More importantly, it has the **highest precision** among all models and reaches the **maximum F1-score (65%)**. While its recall is the lowest among the top contenders, it still maintains the **2nd highest cross-validation score**, suggesting strong generalizability.\n",
    "\n",
    "    This model excels at avoiding **false positives** â€” in other words, itâ€™s cautious about labeling customers as churners unless it's confident.\n",
    "    **Business context:** This helps **minimize unnecessary spending** on retention efforts for customers who aren't likely to churn, making it ideal when retention costs are high and resources need to be used efficiently.\n",
    "\n",
    "2. **Gradient Boost + Random-Under**\n",
    "\n",
    "    This model takes the opposite approach: it achieves the **highest recall (tied)**, meaning itâ€™s best at **catching actual churners**, even at the cost of some false positives. While it has one of the lower accuracy scores, that's expected and acceptable given the class imbalance. It also ties for second in **cross-validation score**, indicating it still performs consistently.\n",
    "\n",
    "    This model is best for **minimizing false negatives** â€” ensuring churners donâ€™t slip through the cracks.\n",
    "    **Business context:** It's ideal in situations where **losing a customer is very costly**, and the priority is to retain as many at-risk customers as possible, even if it means occasionally overreacting.\n",
    "\n",
    "**Overall:** the best model depends on the **business objective**. If the goal is to reduce **unnecessary retention costs**, prioritize precision. If the goal is to **prevent customer loss**, prioritize recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ab390",
   "metadata": {},
   "source": [
    "## Save best model's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24a1f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully Imported Pickle\n"
     ]
    }
   ],
   "source": [
    "#Save best model using pickle\n",
    "\n",
    "#Use try and expect block to install/import pickle\n",
    "try:\n",
    "    import pickle\n",
    "    print('Sucessfully Imported Pickle')\n",
    "except:\n",
    "    !pip install pickle\n",
    "    import pickle\n",
    "    print('Needed to install pickle first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a56e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save best model's using pickle\n",
    "file_to_write_smote = open('telco_churn_best_model_gbc_smote.saved', 'wb')\n",
    "pickle.dump(gbc_smote, file_to_write_smote)\n",
    "file_to_write_smote.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17543a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the same process for Gradient boosting + Under-sampling\n",
    "file_to_write_under = open('telco_churn_best_model_gbc_under.saved', 'wb')\n",
    "pickle.dump(gbc, file_to_write_under)\n",
    "file_to_write_under.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
